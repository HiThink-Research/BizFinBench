<p align="center">
  <h1 align="center">BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs</h1>
    <p align="center">
    <strong>Guilong Lu</strong>
    Â·
    <strong>Xuntao Guo</strong>
    Â·
    <strong>Rongjunchen Zhang</strong>
    Â·
    <strong>Wenqiao Zhu</strong>
    Â·
    <strong>Ji Liu</strong>
  </p>
  ğŸ“–<a href="https://arxiv.org/abs/25xx.xxxxx">Paper</a> |ğŸ <a href="https://hithink-research.github.io/BizFinBench/">Homepage</a></h3>|ğŸ¤—<a href="https://huggingface.co/datasets/HiThink-Research/BizFinBench">Huggingface</a></h3>
<div align="center"></div>
<p align="center">
  <p>
In recent years, multimodal benchmarks for general domains have guided the rapid development of multimodal models on general tasks. However, the financial field has its peculiarities. It features unique graphical images (e.g., candlestick charts, technical indicator charts) and possesses a wealth of specialized financial knowledge (e.g., futures, turnover rate).

Large language models excel across general tasks, yet judging their reliability in logicâ€‘heavy, precisionâ€‘critical domains such as finance, law and healthcare is still difficult. To address this challenge, we propose **BizFinBench**, the first benchmark grounded in real-world financial applications. BizFinBench consists of 6,781 well-annotated queries in Chinese, covering five dimensions: numerical calculation, reasoning, information extraction, prediction recognition and knowledgeâ€based question answering, which are mapped to nine fine-grained categories.

This dataset contains multiple subtasks, each focusing on a different financial understanding and reasoning ability, as follows:

| Dataset                                | Description                                                  | Evaluation Dimensions                                        | Volume |
| -------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| **Anomalous Event Attribution**        | A financial anomaly attribution evaluation dataset assessing models' ability to trace stock fluctuations based on given information (e.g., timestamps, news articles, financial reports, and stock movements). | Causal consistency, information relevance, noise resistance  | 1,064  |
| **Financial Numerical Computation**    | A financial numerical computation dataset evaluating models' ability to perform accurate numerical calculations in financial scenarios, including interest rate calculations, gain/loss computations, etc. | Calculation accuracy, unit consistency                       | 581    |
| **Financial Time Reasoning**           | A financial temporal reasoning evaluation dataset assessing models' ability to comprehend and reason about time-based financial events, such as "the previous trading day" or "the first trading day of the year." | Temporal reasoning correctness                               | 514    |
| **Financial Data Description**         | A financial data description evaluation dataset measuring models' ability to analyze and describe structured/unstructured financial data, e.g., "the stock price first rose to XX before falling to XX." | Trend accuracy, data consistency                             | 1,461  |
| **Stock Price Prediction**             | A stock price movement prediction dataset evaluating models' ability to forecast future stock price trends based on historical data, financial indicators, and market news. | Trend judgment, causal rationality                           | 497    |
| **Financial Named Entity Recognition** | A financial named entity recognition dataset assessing models' ability to identify entities (Person, Organization, Market, Location, Financial Products, Date/Time) in short/long financial news. | Recognition accuracy, entity category correctness            | 433    |
| **Emotion_Recognition**                | A financial sentiment recognition dataset evaluating models' ability to discern nuanced user emotions in complex financial market environments. Inputs include multi-dimensional data such as market conditions, news, research reports, user holdings, and queries, covering six emotion categories: optimism, anxiety, pessimism, excitement, calmness, and regret. | Emotion classification accuracy, implicit information extraction and reasoning correctness | 600    |
| **Financial Tool Usage**               | A financial tool usage dataset evaluating models' ability to understand user queries and appropriately utilize various financial tools (investment analysis, market research, information retrieval, etc.) to solve real-world problems. Tools include calculators, financial encyclopedia queries, search engines, data queries, news queries, economic calendars, and company lookups. Models must accurately interpret user intent, select appropriate tools, input correct parameters, and coordinate multiple tools when necessary. | Tool selection rationality, parameter input accuracy, multi-tool coordination capability | 641    |
| **Financial Knowledge QA**             | A financial encyclopedia QA dataset assessing models' understanding and response accuracy regarding core financial knowledge, covering key domains: financial fundamentals, markets, investment theories, macroeconomics, etc. | Query comprehension accuracy, knowledge coverage breadth, answer accuracy and professionalism | 990    |

## ğŸ“¢ News 
- ğŸš€ [16/05/2025] We released <strong>BizFinBench</strong> benchmark, the first benchmark grounded in real-world financial applications.

## ğŸ’¡ Highlights
- ğŸ”¥  **Benchmark:** We propose **BizFinBench**, the first evaluation benchmark in the financial domain that integrates business-oriented tasks, covering 5 dimensions and 9 categories. It is designed to assess the capacity of LLMs in real-world financial scenarios.
- ğŸ”¥  **Judge model:** We design a novel evaluation method, i.e., **Iterajudge**, which enhances the capability of LLMs as a judge by refining their decision boundaries in specific financial evaluation tasks.
- ğŸ”¥  **key insights:** We conduct a comprehensive evaluation with **25 LLMs** based on BizFinBench, uncovering key insights into their strengths and limitations in financial applications.


## ğŸ› ï¸ Usage

### Contents
```
llm-eval
â”œâ”€â”€ README.md
â”œâ”€â”€ __init__.py
â”œâ”€â”€ benchmark_code
â”œâ”€â”€ config #æ‰€æœ‰çš„è‡ªå®šä¹‰æ ·ä¾‹configå¯ä»¥åœ¨æ­¤æ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°
â”œâ”€â”€ docs #è‡ªåŠ¨ç”Ÿæˆçš„APIæ–‡æ¡£ï¼Œä½¿ç”¨sphinxå®ç°
â”œâ”€â”€ config.yaml #è¿™æ˜¯ä¸€ä¸ªè¯„ä¼°å¼€æºæµ‹è¯•é›†+ä¸šåŠ¡æµ‹è¯•é›†+é‡‘èèƒ½åŠ›æµ‹è¯•é›†çš„é…ç½®æ–‡ä»¶ï¼Œä»…ä¾›å‚è€ƒï¼Œè‡ªå·±éœ€è¦ç»´æŠ¤å¯¹åº”çš„é…ç½®æ–‡ä»¶
â”œâ”€â”€ eval.py
â”œâ”€â”€ inference #æ‰€æœ‰çš„æ¨ç†å¼•æ“ç›¸å…³çš„ä»£ç éƒ½åœ¨æ­¤æ–‡ä»¶å¤¹ä¸‹
â”œâ”€â”€ post_eval.py #æ¨ç†å®Œæˆåçš„è¯„ä¼°å¯åŠ¨ä»£ç 
â”œâ”€â”€ reqirements.txt
â”œâ”€â”€ run.py #æ•´ä¸ªè¿è¡Œæµç¨‹çš„å¯åŠ¨å…¥å£
â”œâ”€â”€ run.sh #è¯„ä¼°å¯åŠ¨çš„æ‰§è¡Œæ–‡ä»¶ï¼Œä»…ä¾›å‚è€ƒï¼Œéœ€è¦è‡ªå·±ç»´æŠ¤è‡ªå·±çš„run.shæ–‡ä»¶
â”œâ”€â”€ run_judge.py
â”œâ”€â”€ scripts #ä¸€äº›å‚è€ƒçš„run.shè„šæœ¬
â”œâ”€â”€ tools #ä¸€äº›å¸¸ç”¨çš„æ–¹æ³•è¿›è¡Œå°è£…ï¼Œå¦‚http requests
â”œâ”€â”€ src
â”œâ”€â”€ statistic.py #ç»Ÿè®¡æœ€ç»ˆè¯„ä¼°ç»“æœå’Œä¸Šä¼ çš„è„šæœ¬
â”œâ”€â”€ testsets #æ‰€æœ‰çš„éä¸šåŠ¡æµ‹è¯•é›†éƒ½åœ¨æ­¤æ–‡ä»¶å¤¹ä¸‹
â””â”€â”€ utils #æ‰€æœ‰çš„æ‰“åˆ†å‡½æ•°éƒ½åœ¨æ­¤æ–‡ä»¶å¤¹ä¸‹
```

### Quick Start è¯„ä¼°æœ¬åœ°æ¨¡å‹ï¼ˆä½¿ç”¨HuggingFace model.generate()å‡½æ•°ï¼‰
<p>è¯„ä¼°æ–°æ¨¡å‹çš„æ—¶å€™æ— æ³•ä½¿ç”¨vllmæ¨ç†æ—¶ï¼Œå¯ä»¥è®¾ç½®backendå‚æ•°ä¸ºhfä½¿ç”¨model.generate()è¿›è¡Œè¯„ä¼°</p>

```sh
export MODEL_PATH=/mnt/data/llm/models/chat/Qwen2.5-0.5B #å¾…è¯„æµ‹æ¨¡å‹éœ€è¦å°†è·¯å¾„æ”¾åœ¨ç¯å¢ƒå˜é‡ä¸­
export REMOTE_MODEL_PORT=16668
export REMOTE_MODEL_URL=http://127.0.0.1:${REMOTE_MODEL_PORT}/model
export MODEL_NAME=Qwen2.5-0.5B
export PROMPT_TYPE=chat_template # Hithink llama3 llama2 none qwen chat_template æ¨èä½¿ç”¨chat_template

#å…ˆå°†æ¨¡å‹å¯åŠ¨ä¸ºæœåŠ¡
python inference/predict_multi_gpu.py --model ${MODEL_PATH} --server_port ${REMOTE_MODEL_PORT} --prompt ${PROMPT_TYPE} --preprocess preprocess --run_forever --max_new_tokens 4096 --tensor_parallel ${TENSOR_PARALLEL} --backend hf & 

#ä¼ å…¥configæ–‡ä»¶è·¯å¾„è¿›è¡Œè¯„æµ‹
python run.py --config config.yaml --model_name ${MODEL_NAME}
```

### Quick Start è¯„ä¼°æœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨å¤§æ¨¡å‹å¯¹è¯„ä¼°ç»“æœæ‰“åˆ†

```sh
export MODEL_PATH=/mnt/data/llm/models/chat/Qwen2.5-0.5B #å¾…è¯„æµ‹æ¨¡å‹éœ€è¦å°†è·¯å¾„æ”¾åœ¨ç¯å¢ƒå˜é‡ä¸­
export REMOTE_MODEL_PORT=16668
export REMOTE_MODEL_URL=http://127.0.0.1:${REMOTE_MODEL_PORT}/model
export MODEL_NAME=Qwen2.5-0.5B
export PROMPT_TYPE=chat_template # Hithink llama3 llama2 none qwen chat_template æ¨èä½¿ç”¨chat_template

#å…ˆå°†æ¨¡å‹å¯åŠ¨ä¸ºæœåŠ¡
python inference/predict_multi_gpu.py --model ${MODEL_PATH} --server_port ${REMOTE_MODEL_PORT} --prompt ${PROMPT_TYPE} --preprocess preprocess --run_forever --max_new_tokens 4096 --tensor_parallel ${TENSOR_PARALLEL} --low_vram & 

# å¯åŠ¨è£åˆ¤å‘˜æ¨¡å‹
export JUDGE_MODEL_PATH=/mnt/data/llm/models/base/Qwen2.5-7B
export JUDGE_TENSOR_PARALLEL=1
export JUDGE_MODEL_PORT=16667
python inference/predict_multi_gpu.py --model ${JUDGE_MODEL_PATH} --server_port ${JUDGE_MODEL_PORT} --prompt chat_template --preprocess preprocess  --run_forever --manual_start --max_new_tokens 4096 --tensor_parallel ${JUDGE_TENSOR_PARALLEL} --low_vram &

# ä¼ å…¥configæ–‡ä»¶è·¯å¾„è¿›è¡Œè¯„æµ‹
python run.py --config "config_all_yewu.yaml" --model_name ${MODEL_NAME}
```
æ³¨æ„åœ¨å¯åŠ¨è£åˆ¤å‘˜æ¨¡å‹æ—¶å¢åŠ äº†`--manual_start`å…¥å‚ï¼Œå› ä¸ºè£åˆ¤å‘˜æ¨¡å‹éœ€è¦ç­‰å¾…æ¨¡å‹æ¨ç†å®Œæˆåå†å¯åŠ¨ï¼ˆç”±`run.py`ä¸­çš„`maybe_start_judge_model`æ–¹æ³•è‡ªåŠ¨è§¦å‘ï¼‰ã€‚

## âœ’ï¸Citation

comming soon

## ğŸ“„ License
![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg) ![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg) **Usage and License Notices**: The data and code are intended and licensed for research use only.
License: Attribution-NonCommercial 4.0 International It should abide by the policy of OpenAI: https://openai.com/policies/terms-of-use

## ğŸ’– Acknowledgement
* We would like to thank [Weijie Zhang](https://github.com/zhangwj618) for his contribution to the development of the inference engine.
* This work leverages [vLLM](https://github.com/vllm-project/vllm) as the backend model server for evaluation purposes.
